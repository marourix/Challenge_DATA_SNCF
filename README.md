# ğŸ“Š PrÃ©diction de la Variable `p0q0` â€“ Analyse, Nettoyage et ModÃ©lisation

## ğŸ§¾ Description du Projet

Ce projet vise Ã  prÃ©dire la variable continue **`p0q0`** Ã  partir de donnÃ©es issues de capteurs ou de systÃ¨mes liÃ©s Ã  des **gares** et des **trains**. Lâ€™objectif est de construire un pipeline complet incluant lâ€™exploration, le nettoyage, lâ€™encodage, la normalisation et l'entraÃ®nement de plusieurs modÃ¨les de rÃ©gression, avec un accent particulier sur lâ€™optimisation des hyperparamÃ¨tres du modÃ¨le **XGBoost** Ã  lâ€™aide de **Optuna**.

---

## ğŸ“ Fichiers

- `x_train_final.csv` : Jeu de donnÃ©es contenant les variables explicatives.
- `y_train_final_j5KGWWK.csv` : Fichier contenant la variable cible `p0q0`.
- `main.py` : Code principal du projet.
- `README.md` : Ce fichier.

---

## âš™ï¸ Ã‰tapes de Traitement

### 1. ğŸ” Exploration et PrÃ©traitement

- Suppression des colonnes `Unnamed`.
- Analyse de la structure des donnÃ©es (`info`, `describe`, histogrammes).
- Visualisation des outliers via **boxplots**.

### 2. ğŸ§¹ Nettoyage

- **Suppression des outliers** : mÃ©thode de lâ€™**IQR**.
- VÃ©rification de la distribution de la cible avant/aprÃ¨s nettoyage.

### 3. ğŸ“† Traitement des Dates

- Extraction du jour de la semaine.
- **Encodage cyclique** avec sinus et cosinus.

### 4. ğŸ”¢ Encodage des Variables CatÃ©gorielles

- **Encodage OneHot** de la variable `gare`.
- **Label Encoding** de la variable `train`.

### 5. âš–ï¸ Normalisation

- Utilisation du **RobustScaler** (rÃ©sistant aux outliers).

### 6. ğŸ§  EntraÃ®nement de ModÃ¨les

- **RÃ©gression LinÃ©aire** (baseline).
- **XGBoost Regressor** avec **tuning dâ€™hyperparamÃ¨tres via Optuna**.

---

## ğŸ§ª ModÃ¨les UtilisÃ©s

| ModÃ¨le                | MAE (exemple) 
|-----------------------|---------------
| RÃ©gression LinÃ©aire   | 0,66        |
| XGBoost (tuned) Optuna     |  0,58       |



---

## ğŸ§  Optimisation avec Optuna

- **Optuna** est utilisÃ© pour optimiser automatiquement les hyperparamÃ¨tres de **XGBoost**.
- ParamÃ¨tres optimisÃ©s : `n_estimators`, `learning_rate`, `max_depth`, `subsample`, `colsample_bytree`, `reg_alpha`, `reg_lambda`.
- MÃ©trique de validation : **MAE** (erreur absolue moyenne) via **validation croisÃ©e**.

---

## ğŸ“ˆ Visualisations ClÃ©s

- Histogrammes et boxplots de la cible `p0q0`.
- Matrice de corrÃ©lation entre variables numÃ©riques.
- Distributions aprÃ¨s nettoyage.

---

## ğŸ› ï¸ Librairies UtilisÃ©es

```python
pandas, numpy, matplotlib, seaborn, sklearn, xgboost, optuna

---



